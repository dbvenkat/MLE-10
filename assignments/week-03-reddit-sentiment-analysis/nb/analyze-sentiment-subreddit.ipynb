{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align = \"center\" draggable=‚Äùfalse‚Äù ><img src=\"https://user-images.githubusercontent.com/37101144/161836199-fdb0219d-0361-4988-bf26-48b0fad160a3.png\" \n",
    "     width=\"200px\"\n",
    "     height=\"auto\"/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1 align=\"center\" id=\"heading\">Sentiment Analysis of Reddit Data using Reddit API</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this live coding session, we leverage the Python Reddit API Wrapper (`PRAW`) to retrieve data from subreddits on [Reddit](https://www.reddit.com), and perform sentiment analysis using [`pipelines`](https://huggingface.co/docs/transformers/main_classes/pipelines) from [HuggingFace ( ü§ó the GitHub of Machine Learning )](https://techcrunch.com/2022/05/09/hugging-face-reaches-2-billion-valuation-to-build-the-github-of-machine-learning/), powered by [transformer](https://arxiv.org/pdf/1706.03762.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of the session, you will "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- know how to work with APIs\n",
    "- feel more comfortable navigating thru documentation, even inspecting the source code\n",
    "- understand what a `pipeline` object is in HuggingFace\n",
    "- perform sentiment analysis using `pipeline`\n",
    "- run a python script in command line and get the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## How to Submit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- At the end of each task, commit* the work into the repository you created before the assignment\n",
    "- After completing all three tasks, make sure to push the notebook containing all code blocks and output cells to your repository you created before the assignment\n",
    "- Submit the link to the notebook in Canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\\***NEVER** commit a notebook displaying errors unless it is instructed otherwise. However, commit often; recall git ABC = **A**lways **B**e **C**ommitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Task I: Instantiate a Reddit API Object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The first task is to instantiate a Reddit API object using [PRAW](https://praw.readthedocs.io/en/stable/), through which you will retrieve data. PRAW is a wrapper for [Reddit API](https://www.reddit.com/dev/api) that makes interacting with the Reddit API easier unless you are already an expert of [`requests`](https://docs.python-requests.org/en/latest/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 1. Install packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Please ensure you've ran all the cells in the `imports.ipynb`, located [here](https://github.com/FourthBrain/MLE-8/blob/main/assignments/week-3-analyze-sentiment-subreddit/imports.ipynb), to make sure you have all the required packages for today's assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "####  2. Create a new app on Reddit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Create a new app on Reddit and save secret tokens; refer to [post in medium](https://towardsdatascience.com/how-to-use-the-reddit-api-in-python-5e05ddfd1e5c) for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Create a Reddit account if you don't have one, log into your account.\n",
    "- To access the API, we need create an app. Slight updates, on the website, you need to navigate to `preference` > `app`, or click [this link](https://www.reddit.com/prefs/apps) and scroll all the way down. \n",
    "- Click to create a new app, fill in the **name**, choose `script`, fill in  **description** and **redirect uri** ( The redirect URI is where the user is sent after they've granted OAuth access to your application (more info [here](https://github.com/reddit-archive/reddit/wiki/OAuth2)) For our purpose, you can enter some random url, e.g., www.google.com; as shown below.\n",
    "\n",
    "\n",
    "    <img src=\"https://miro.medium.com/max/700/1*lRBvxpIe8J2nZYJ6ucMgHA.png\" width=\"500\"/>\n",
    "- Jot down `client_id` (left upper corner) and `client_secret` \n",
    "\n",
    "    NOTE: CLIENT_ID refers to 'personal use script\" and CLIENT_SECRET to secret.\n",
    "    \n",
    "    <div>\n",
    "    <img src=\"https://miro.medium.com/max/700/1*7cGAKth1PMrEf2sHcQWPoA.png\" width=\"300\"/>\n",
    "    </div>\n",
    "\n",
    "- Create `secrets_reddit.py` in the same directory with this notebook, fill in `client_id` and `secret_id` obtained from the last step. We will need to import those constants in the next step.\n",
    "    ```\n",
    "    REDDIT_API_CLIENT_ID = \"client_id\"\n",
    "    REDDIT_API_CLIENT_SECRET = \"secret_id\"\n",
    "    REDDIT_API_USER_AGENT = \"any string except bot; ex. My User Agent\"\n",
    "    ```\n",
    "- Add `secrets_reddit.py` to your `.gitignore` file if not already done. NEVER push credentials to a repo, private or public. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 3. Instantiate a `Reddit` object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now you are ready to create a read-only `Reddit` instance. Refer to [documentation](https://praw.readthedocs.io/en/stable/code_overview/reddit_instance.html) when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import praw\n",
    "from secrets_reddit import reddit_secrets as rs\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=rs[\"REDDIT_API_CLIENT_ID\"],\n",
    "    client_secret=rs[\"REDDIT_API_CLIENT_SECRET\"],\n",
    "    user_agent=rs[\"REDDIT_API_USER_AGENT\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(reddit.read_only) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected output:</summary>   \n",
    "\n",
    "```<praw.reddit.Reddit object at 0x10f8a0ac0>```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 4. Instantiate a `subreddit` object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Lastly, create a `subreddit` object for your favorite subreddit and inspect the object. The expected output you will see ar from `r/machinelearning` unless otherwise specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "s_ml = reddit.subreddit(\"machinelearning\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What is the display name of the subreddit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'machinelearning'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_ml.display_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected output:</summary>   \n",
    "\n",
    "    machinelearning\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "How about its title, is it different from the display name?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Machine Learning'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_ml.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected output:</summary>   \n",
    "\n",
    "    Machine Learning\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Print out the description of the subreddit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**[Rules For Posts](https://www.reddit.com/r/MachineLearning/about/rules/)**\n",
      "--------\n",
      "+[Research](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3AResearch)\n",
      "--------\n",
      "+[Discussion](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3ADiscussion)\n",
      "--------\n",
      "+[Project](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3AProject)\n",
      "--------\n",
      "+[News](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3ANews)\n",
      "--------\n",
      "***[@slashML on Twitter](https://twitter.com/slashML)***\n",
      "--------\n",
      "***[Chat with us on Slack](https://join.slack.com/t/rml-talk/shared_invite/enQtNjkyMzI3NjA2NTY2LWY0ZmRjZjNhYjI5NzYwM2Y0YzZhZWNiODQ3ZGFjYmI2NTU3YjE1ZDU5MzM2ZTQ4ZGJmOTFmNWVkMzFiMzVhYjg)***\n",
      "--------\n",
      "**Beginners:**\n",
      "--------\n",
      "Please have a look at [our FAQ and Link-Collection](http://www.reddit.com/r/MachineLearning/wiki/index)\n",
      "\n",
      "[Metacademy](http://www.metacademy.org) is a great resource which compiles lesson plans on popular machine learning topics.\n",
      "\n",
      "For Beginner questions please try /r/LearnMachineLearning , /r/MLQuestions or http://stackoverflow.com/\n",
      "\n",
      "For career related questions, visit /r/cscareerquestions/\n",
      "\n",
      "--------\n",
      "\n",
      "[Advanced Courses (2016)](https://www.reddit.com/r/MachineLearning/comments/51qhc8/phdlevel_courses?st=isz2lqdk&sh=56c58cd6)\n",
      "\n",
      "[Advanced Courses (2020)](https://www.reddit.com/r/MachineLearning/comments/fdw0ax/d_advanced_courses_update/)\n",
      "\n",
      "--------\n",
      "**AMAs:**\n",
      "\n",
      "[Pluribus Poker AI Team 7/19/2019](https://www.reddit.com/r/MachineLearning/comments/ceece3/ama_we_are_noam_brown_and_tuomas_sandholm/)\n",
      "\n",
      "[DeepMind AlphaStar team (1/24//2019)](https://www.reddit.com/r/MachineLearning/comments/ajgzoc/we_are_oriol_vinyals_and_david_silver_from/)\n",
      "\n",
      "[Libratus Poker AI Team (12/18/2017)]\n",
      "(https://www.reddit.com/r/MachineLearning/comments/7jn12v/ama_we_are_noam_brown_and_professor_tuomas/)\n",
      "\n",
      "[DeepMind AlphaGo Team (10/19/2017)](https://www.reddit.com/r/MachineLearning/comments/76xjb5/ama_we_are_david_silver_and_julian_schrittwieser/)\n",
      "\n",
      "[Google Brain Team (9/17/2017)](https://www.reddit.com/r/MachineLearning/comments/6z51xb/we_are_the_google_brain_team_wed_love_to_answer/)\n",
      "\n",
      "[Google Brain Team (8/11/2016)]\n",
      "(https://www.reddit.com/r/MachineLearning/comments/4w6tsv/ama_we_are_the_google_brain_team_wed_love_to/)\n",
      "\n",
      "[The MalariaSpot Team (2/6/2016)](https://www.reddit.com/r/MachineLearning/comments/4m7ci1/ama_the_malariaspot_team/)\n",
      "\n",
      "[OpenAI Research Team (1/9/2016)](http://www.reddit.com/r/MachineLearning/comments/404r9m/ama_the_openai_research_team/)\n",
      "\n",
      "[Nando de Freitas (12/26/2015)](http://www.reddit.com/r/MachineLearning/comments/3y4zai/ama_nando_de_freitas/)\n",
      "\n",
      "[Andrew Ng and Adam Coates (4/15/2015)](http://www.reddit.com/r/MachineLearning/comments/32ihpe/ama_andrew_ng_and_adam_coates/)\n",
      "\n",
      "[J√ºrgen Schmidhuber (3/4/2015)](http://www.reddit.com/r/MachineLearning/comments/2xcyrl/i_am_j%C3%BCrgen_schmidhuber_ama/)\n",
      "\n",
      "[Geoffrey Hinton (11/10/2014)]\n",
      "(http://www.reddit.com/r/MachineLearning/comments/2lmo0l/ama_geoffrey_hinton/)\n",
      "\n",
      "[Michael Jordan (9/10/2014)](http://www.reddit.com/r/MachineLearning/comments/2fxi6v/ama_michael_i_jordan/)\n",
      "\n",
      "[Yann LeCun (5/15/2014)](http://www.reddit.com/r/MachineLearning/comments/25lnbt/ama_yann_lecun/)\n",
      "\n",
      "[Yoshua Bengio (2/27/2014)](http://www.reddit.com/r/MachineLearning/comments/1ysry1/ama_yoshua_bengio/)\n",
      "\n",
      "--------\n",
      "Related Subreddit :\n",
      "\n",
      "* [LearnMachineLearning](http://www.reddit.com/r/LearnMachineLearning)\n",
      "\n",
      "* [Statistics](http://www.reddit.com/r/statistics)\n",
      "\n",
      "* [Computer Vision](http://www.reddit.com/r/computervision)\n",
      "\n",
      "* [Compressive Sensing](http://www.reddit.com/r/CompressiveSensing/)\n",
      "\n",
      "* [NLP] (http://www.reddit.com/r/LanguageTechnology)\n",
      "\n",
      "* [ML Questions] (http://www.reddit.com/r/MLQuestions)\n",
      "\n",
      "* /r/MLjobs and /r/BigDataJobs\n",
      "\n",
      "* /r/datacleaning\n",
      "\n",
      "* /r/DataScience\n",
      "\n",
      "* /r/scientificresearch\n",
      "\n",
      "* /r/artificial\n"
     ]
    }
   ],
   "source": [
    "print(s_ml.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Expected output:</summary>\n",
    "\n",
    "    **[Rules For Posts](https://www.reddit.com/r/MachineLearning/about/rules/)**\n",
    "    --------\n",
    "    +[Research](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3AResearch)\n",
    "    --------\n",
    "    +[Discussion](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3ADiscussion)\n",
    "    --------\n",
    "    +[Project](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict_sr=on&q=flair%3AProject)\n",
    "    --------\n",
    "    +[News](https://www.reddit.com/r/MachineLearning/search?sort=new&restrict\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Task II: Parse comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 1. Top Posts of All Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Find titles of top 10 posts of **all time** from your favorite subreddit. Refer to [Obtain Submission Instances from a Subreddit Section](https://praw.readthedocs.io/en/stable/getting_started/quick_start.html)) if necessary. Verify if the titles match what you read on Reddit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# try run this line, what do you see? press q once you are done\n",
    "?subreddit.top "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Project] From books to presentations in 10s with AR + ML\n",
      "[D] A Demo from 1993 of 32-year-old Yann LeCun showing off the World's first Convolutional Network for Text Recognition\n",
      "[R] First Order Motion Model applied to animate paintings\n",
      "[N] AI can turn old photos into moving Images / Link is given in the comments - You can also turn your old photo like this\n",
      "[D] This AI reveals how much time politicians stare at their phone at work\n",
      "[D] Types of Machine Learning Papers\n",
      "[D] The machine learning community has a toxicity problem\n",
      "I made a robot that punishes me if it detects that if I am procrastinating on my assignments [P]\n",
      "[Project] NEW PYTHON PACKAGE: Sync GAN Art to Music with \"Lucid Sonic Dreams\"! (Link in Comments)\n",
      "[P] Using oil portraits and First Order Model to bring the paintings back to life\n"
     ]
    }
   ],
   "source": [
    "for submission in s_ml.top(limit=10, time_filter=\"all\"):\n",
    "    print(submission.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details> <summary>Expected output:</summary>\n",
    "\n",
    "    [Project] From books to presentations in 10s with AR + ML\n",
    "    [D] A Demo from 1993 of 32-year-old Yann LeCun showing off the World's first Convolutional Network for Text Recognition\n",
    "    [R] First Order Motion Model applied to animate paintings\n",
    "    [N] AI can turn old photos into moving Images / Link is given in the comments - You can also turn your old photo like this\n",
    "    [D] This AI reveals how much time politicians stare at their phone at work\n",
    "    [D] Types of Machine Learning Papers\n",
    "    [D] The machine learning community has a toxicity problem\n",
    "    [Project] NEW PYTHON PACKAGE: Sync GAN Art to Music with \"Lucid Sonic Dreams\"! (Link in Comments)\n",
    "    [P] Using oil portraits and First Order Model to bring the paintings back to life\n",
    "    [D] Convolution Neural Network Visualization - Made with Unity 3D and lots of Code / source - stefsietz (IG)    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 2. Top 10 Posts of This Week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What are the titles of the top 10 posts of **this week** from your favorite subreddit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[P][R] Modern Disney Diffusion, dreambooth model trained using the diffusers implementation\n",
      "[P] Finetuned Diffusion: multiple fine-tuned Stable Diffusion models, trained on different styles\n",
      "[P] Explain Paper - A Better Way to Read Academic Papers\n",
      "[R] TOCH outperforms state of the art 3D hand-object interaction models and produces smooth interactions even before and after contact\n",
      "[D] DALL¬∑E to be made available as API, OpenAI to give users full ownership rights to generated images\n",
      "[P] Made a text generation model to extend stable diffusion prompts with suitable style cues\n",
      "[P] Learn diffusion models with Hugging Face course üß®\n",
      "[News] The Stack: 3 TB of permissively licensed source code - Hugging Face and ServiceNow Research Denis Kocetkov et al 2022\n",
      "[N] Adversarial Policies Beat Professional-Level Go AIs\n",
      "[P] Fine Tuning Stable Diffusion: Naruto Character Edition\n"
     ]
    }
   ],
   "source": [
    "for submission in s_ml.top(limit=10, time_filter=\"week\"):\n",
    "    print(submission.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<details><summary>Expected output:</summary>\n",
    "\n",
    "    [N] Ian Goodfellow, Apple‚Äôs director of machine learning, is leaving the company due to its return to work policy. In a note to staff, he said ‚ÄúI believe strongly that more flexibility would have been the best policy for my team.‚Äù He was likely the company‚Äôs most cited ML expert.\n",
    "    [R][P] Thin-Plate Spline Motion Model for Image Animation + Gradio Web Demo\n",
    "    [P] I‚Äôve been trying to understand the limits of some of the available machine learning models out there. Built an app that lets you try a mix of CLIP from Open AI + Apple‚Äôs version of MobileNet, and more directly on your phone's camera roll.\n",
    "    [R] Meta is releasing a 175B parameter language model\n",
    "    [N] Hugging Face raised $100M at $2B to double down on community, open-source & ethics\n",
    "    [P] T-SNE to view and order your Spotify tracks\n",
    "    [D] : HELP Finding a Book - A book written for Google Engineers about foundational Math to support ML\n",
    "    [R] Scaled up CLIP-like model (~2B) shows 86% Zero-shot on Imagenet\n",
    "    [D] Do you use NLTK or Spacy for text preprocessing?\n",
    "    [D] Democratizing Diffusion Models - LDMs: High-Resolution Image Synthesis with Latent Diffusion Models, a 5-minute paper summary by Casual GAN Papers\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üíΩ‚ùì Data Question:\n",
    "\n",
    "Check out what other attributes the `praw.models.Submission` class has in the [docs](https://praw.readthedocs.io/en/stable/code_overview/models/submission.html). \n",
    "\n",
    "1. After having a chance to look through the docs, is there any other information that you might want to extract? How might this additional data help you?\n",
    "\n",
    "Write a sample piece of code below extracting three additional pieces of information from the submission below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ex - Redirect to /r/MachineLearning/login/ (You may be trying to perform a non-read-only action via a read-only instance.)\n"
     ]
    }
   ],
   "source": [
    "#s_ml.traffic() - Doesn't seem to like this and throws an exception\n",
    "try:\n",
    "    stats = s_ml.traffic()\n",
    "except Exception as ex:\n",
    "    print(f\"Ex - {ex}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to perform economic optimization without TensorFlow or PyTorch ? [Research]\n",
      "[P] Finetuned Diffusion: multiple fine-tuned Stable Diffusion models, trained on different styles\n",
      "[D] Paper Explanation & Author Interview - ROME: Locating and Editing Factual Associations in GPT\n",
      "[Discussion] ICLR2023 statistics of submission\n",
      "[D] Physics-inspired Deep Learning Models\n",
      "[P] Learn diffusion models with Hugging Face course üß®\n",
      "[D] ICLR 2023 reviews are out. How was your experience ?\n",
      "[P] Sparse Transformers for Inference in a Real-Time Twitter Stream\n",
      "[D] NVIDIA RTX 4090 vs RTX 3090 Deep Learning Benchmarks\n",
      "[D] A model with different data types as input?\n",
      "[N] AAAI2023 workshop on Dynamical Systems and Machine Learning\n",
      "[P] Topic modeling with semantic graphs: a different approach\n",
      "[D] Paper bidding is a terrible system\n"
     ]
    }
   ],
   "source": [
    "#Rising submissions\n",
    "for rising_submission in s_ml.rising():\n",
    "    print(rising_submission.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emilec___\n",
      "FutureWatch4\n",
      "llSourcell\n",
      "datadudes-ai\n",
      "improssibility\n",
      "No_Effective7572\n",
      "depressedPOS-plzhelp\n",
      "sour_losers\n",
      "otoyou1234\n",
      "throwmeaway-account\n"
     ]
    }
   ],
   "source": [
    "#See who has posted controversial comments\n",
    "for controversial_comments in s_ml.controversial(limit=10):\n",
    "    if controversial_comments:\n",
    "        print(controversial_comments.author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LUNA_underUrsaMajor\n",
      "RoboticCougar\n",
      "ForceBru\n",
      "ShadowKnightPro\n",
      "AutoModerator\n"
     ]
    }
   ],
   "source": [
    "#Comment author is useful if we want to know who commented or if we want to see if a specific person has commented\n",
    "for comment in s_ml.comments(limit=5):\n",
    "    print(comment.author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üíΩ‚ùì Data Question:\n",
    "\n",
    "2. Is there any information available that might be a concern when it comes to Ethical Data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the first pass, it doesn't look like it. \n",
    "#Author information could be one but doesn't look like it could be used for hacking purposes. \n",
    "#People can always post things that are unethical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 3. Comment Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Add comments to the code block below to describe what each line of the code does (Refer to [Obtain Comment Instances Section](https://praw.readthedocs.io/en/stable/getting_started/quick_start.html) when necessary). The code is adapted from [this tutorial](https://praw.readthedocs.io/en/stable/tutorials/comments.html)\n",
    "\n",
    "The purpose is \n",
    "1. to understand what the code is doing \n",
    "2. start to comment your code whenever it is not self-explantory if you have not (others will thank you, YOU will thank you later üòä) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "746\n",
      "CPU times: user 486 ms, sys: 30.6 ms, total: 517 ms\n",
      "Wall time: 1min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from praw.models import MoreComments\n",
    "\n",
    "# A list to store the comments for the top posts\n",
    "top_comments = []\n",
    "\n",
    "# Iterate through the top 10 posts\n",
    "for submission in s_ml.top(limit=10):\n",
    "    # Iterate through comments for each post\n",
    "    for top_level_comment in submission.comments:\n",
    "        # Ignore if what is returned is an instance of MoreComments\n",
    "        if isinstance(top_level_comment, MoreComments):\n",
    "            continue\n",
    "        # Append the comment body to list of top comments\n",
    "        top_comments.append(top_level_comment.body)\n",
    "print(len(top_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### 4. Inspect Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "How many comments did you extract from the last step? Examine a few comments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#YOUR CODE HERE  # the answer may vary 693 for r/machinelearning\n",
    "746"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My cat HATED that omg.',\n",
       " \"Calm down, young one, too much drama ;)\\n\\nA lot has changed over the past ~5 years, and the machine learning field really raised the bar on standards imho.\\n\\nPapers are no longer behind a paywall? And there's code to go with it and results can be reproduced? And open datasets to benchmark against? Ya kidding me? 10 years ago if you took latest state of the art paper and implemented it yourself, you'd find out your performance is somehow worse. That maybe some magic values were not mentioned. Or they hand-picked test sequences. Etc.\\n\\nPeople worship Google or Stanford? Few years back, the fashion was about publishing in Nature and Science and chasing impact factors. Either way, exceptional work gets recognized, that's the best you can do anyway. Get published on merit.\\n\\nSo, worried about publishing by all means, marginally pushing the envelope on state of the art and mostly just tinkering with hyper parameters until you get the result you wanted? That's just what academia has been about the past 40 years. It's an issue worth addressing, sure, but it is  not recent and not unique to any given field.\\n\\nAs for the rest.. about sexism, biased datasets, Twitter scandals or democratizing AI.. That's just the scandal of the day. In the end, opinions are like farts.. everyone has them, but maybe it's better to keep it to yourself.\",\n",
       " 'I love every one of these, but the deep learning one hits most home to what I have to deal with . ;)']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "[random.choice(top_comments) for i in range(3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details> <summary>Some of the comments from `r/machinelearning` subreddit are:</summary>\n",
    "\n",
    "    ['Awesome visualisation',\n",
    "    'Similar to a stack or connected neurons.',\n",
    "    'Will this Turing pass the Turing Test?']\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üíΩ‚ùì Data Question:\n",
    "\n",
    "3. After having a chance to review a few samples of 5 comments from the subreddit, what can you say about the data? \n",
    "\n",
    "HINT: Think about the \"cleanliness\" of the data, the content of the data, think about what you're trying to do - how does this data line up with your goal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comments like the first one don't have value and the second is just rambling. Third one might have value.\n",
    "# The data istself is raw and so will need some filtering\n",
    "# Depending on what we are looking for, we'll have to more due diligence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 5. Extract Top Level Comment from Subreddit `TSLA`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Write your code to extract top level comments from the top 10 topics of a time period, e.g., year, from subreddit `TSLA` and store them in a list `top_comments_tsla`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 183 ms, sys: 16.7 ms, total: 200 ms\n",
      "Wall time: 3.29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from praw.models import MoreComments\n",
    "\n",
    "# A list to store the comments for the top posts\n",
    "top_comments_tsla = []\n",
    "\n",
    "# Iterate through the top 10 posts\n",
    "for submission in reddit.subreddit('TSLA').top(limit=10):\n",
    "    # Iterate through comments for each post\n",
    "    for top_level_comment in submission.comments:\n",
    "        # Ignore if what is returned is an instance of MoreComments\n",
    "        if isinstance(top_level_comment, MoreComments):\n",
    "            continue\n",
    "        # Append the comment body to list of top comments\n",
    "        top_comments_tsla.append(top_level_comment.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "170"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_comments_tsla) # Expected: 174 for r/machinelearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['**Fell of the chair.. Awesomely put together**',\n",
       " '[deleted]',\n",
       " 'I saw a Tesla go from $173 to $1500. Elon musk is a beast. He‚Äôs always fighting off the short sellers and still on top. It‚Äôs like all the Rocky movies doesn‚Äôt matter how many times you hit him he just keeps coming back until you‚Äôre too weak to fight back and then Bam a legend is made. Don‚Äôt take my word for it do you‚Äôre own  research. If I had a nickel for every time I heard someone say I wish I would‚Äôve bought it when it was low....']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[random.choice(top_comments_tsla) for i in range(3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Some of the comments from `r/TSLA` subreddit:</summary>\n",
    "\n",
    "    ['I bought puts',\n",
    "    '100%',\n",
    "    'Yes. And I‚Äôm bag holding 1200 calls for Friday and am close to throwing myself out the window']\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üíΩ‚ùì Data Question:\n",
    "\n",
    "4. Now that you've had a chance to review another subreddits comments, do you see any differences in the kinds of comments either subreddit has - and how might this relate to bias?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The comments are look a more vociferous \n",
    "# Obviously comments are from folks interested in Tesla stock and their very biased opinions\n",
    "# I'm sure comments for machine learning can also be as biased but may be we didn't see any"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Task III: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let us analyze the sentiment of comments scraped from `r/TSLA` using a pre-trained HuggingFace model to make the inference. Take a [Quick tour](https://huggingface.co/docs/transformers/quicktour). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 1. Import `pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 2. Create a Pipeline to Perform Task \"sentiment-analysis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6a80e3aecce427aba79520b45553c28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.45k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentiment_model = pipeline(model=\"finiteautomata/bertweet-base-sentiment-analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 3. Get one comment from list `top_comments_tsla` from Task II - 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "comment = random.choice(top_comments_tsla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ho lee fuk \\n\\nyou got anymore insider information? üëÄüëÄ'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example comment is: `'Bury Burry!!!!!'`. Print out what you get. For reproducibility, use the same comment in the next step; consider setting a seed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### 4. Make Inference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "sentiment = sentiment_model(comment)\n",
    "print(type(sentiment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What is the type of the output `sentiment`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "It is a  List\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The comment: ho lee fuk \n",
      "\n",
      "you got anymore insider information? üëÄüëÄ\n",
      "Predicted Label is NEG and the score is 0.951\n"
     ]
    }
   ],
   "source": [
    "print(f'The comment: {comment}')\n",
    "print(f'Predicted Label is {sentiment[0][\"label\"]} and the score is {sentiment[0][\"score\"]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the example comment, the output is:\n",
    "\n",
    "    The comment: Bury Burry!!!!!\n",
    "    Predicted Label is NEGATIVE and the score is 0.989"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üñ•Ô∏è‚ùì Model Question:\n",
    "\n",
    "1. What does the score represent?\n",
    "\n",
    "The score represents how sure the model is with respect to the sentiment. In here the score is 0.951 and so the model is pretty sure that the sentiment is negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task IV: Put All Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pull all the piece together, create a simple script that does \n",
    "\n",
    "- get the subreddit\n",
    "- get comments from the top posts for given subreddit\n",
    "- run sentiment analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complete the Script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you complete the code, running the following block writes the code into a new Python script and saves it as `top_tlsa_comment_sentiment.py` under the same directory with the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting top_tlsa_comment_sentiment.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile top_tlsa_comment_sentiment.py\n",
    "\n",
    "import secrets\n",
    "import random\n",
    "\n",
    "from typing import Dict, List\n",
    "\n",
    "from praw import Reddit\n",
    "from praw.models.reddit.subreddit import Subreddit\n",
    "from praw.models import MoreComments\n",
    "\n",
    "from transformers import pipeline\n",
    "from secrets_reddit import reddit_secrets as rs\n",
    "\n",
    "\n",
    "def get_subreddit(display_name:str) -> Subreddit:\n",
    "    \"\"\"Get subreddit object from display name\n",
    "\n",
    "    Args:\n",
    "        display_name (str): [description]\n",
    "\n",
    "    Returns:\n",
    "        Subreddit: [description]\n",
    "    \"\"\"\n",
    "    reddit = Reddit(\n",
    "        client_id=rs[\"REDDIT_API_CLIENT_ID\"],\n",
    "        client_secret=rs[\"REDDIT_API_CLIENT_SECRET\"],\n",
    "        user_agent=rs[\"REDDIT_API_USER_AGENT\"],\n",
    "#        client_id=secrets.REDDIT_API_CLIENT_ID,        \n",
    "#        client_secret=secrets.REDDIT_API_CLIENT_SECRET,\n",
    "#        user_agent=secrets.REDDIT_API_USER_AGENT\n",
    "        )\n",
    "    \n",
    "    subreddit = reddit.subreddit(display_name)\n",
    "    return subreddit\n",
    "\n",
    "def get_comments(subreddit:Subreddit, limit:int=3) -> List[str]:\n",
    "    \"\"\" Get comments from subreddit\n",
    "\n",
    "    Args:\n",
    "        subreddit (Subreddit): [description]\n",
    "        limit (int, optional): [description]. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of comments\n",
    "    \"\"\"\n",
    "    top_comments = []\n",
    "    for submission in subreddit.top(limit=limit):\n",
    "        for top_level_comment in submission.comments:\n",
    "            if isinstance(top_level_comment, MoreComments):\n",
    "                continue\n",
    "            top_comments.append(top_level_comment.body)\n",
    "    return top_comments\n",
    "\n",
    "def run_sentiment_analysis(comment:str) -> Dict:\n",
    "    \"\"\"Run sentiment analysis on comment using default distilbert model\n",
    "    \n",
    "    Args:\n",
    "        comment (str): [description]\n",
    "        \n",
    "    Returns:\n",
    "        str: Sentiment analysis result\n",
    "    \"\"\"\n",
    "#    sentiment_model = pipeline(model=\"finiteautomata/bertweet-base-sentiment-analysis\")\n",
    "    sentiment_model = pipeline(\"sentiment-analysis\")\n",
    "    sentiment = sentiment_model(comment)\n",
    "    return sentiment[0]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    subreddit = get_subreddit(\"TSLA\")\n",
    "    comments = get_comments(subreddit)\n",
    "    comment = random.choice(comments)\n",
    "    sentiment = run_sentiment_analysis(comment)\n",
    "    \n",
    "    print(f'The comment: {comment}')\n",
    "    print(f'Predicted Label is {sentiment[\"label\"]} and the score is {sentiment[\"score\"]:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following block to see the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "The comment: FACTS SIR!!!üòíüòåüòîüò™\n",
      "Predicted Label is POSITIVE and the score is 0.996\n"
     ]
    }
   ],
   "source": [
    "!python top_tlsa_comment_sentiment.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary> Expected output:</summary>\n",
    "\n",
    "    No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n",
    "    The comment: When is DOGE flying\n",
    "    Predicted Label is POSITIVE and the score is 0.689\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.806451612903224\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "subreddit = 'machinelearning'\n",
    "import datetime as dt\n",
    "\n",
    "after = int(dt.datetime(2022,10,7,21,0).timestamp())\n",
    "r = requests.get(f\"https://api.pushshift.io/reddit/search/submission/?subreddit={subreddit}&metadata=true&size=0&after={after}\")\n",
    "\n",
    "print(r.json()['metadata']['total_results']/31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üíΩ‚ùì Data Question:\n",
    "\n",
    "5. Is the subreddit active? About how many posts or threads per day? How could you find this information?\n",
    "\n",
    "Doesn't look like there is a simple way to do it. I googled and found the way that I have used above to be the simplest although I'm not entirely sure if that is the case. Either way, it seems like there are only 58 posts per day on an average in the last 31 days for \"machinelearning\" and so it is active but not very active, I guess."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Redditor(name='Illustrious_Row_9971'), 49),\n",
       " (None, 34),\n",
       " (Redditor(name='hardmaru'), 22),\n",
       " (Redditor(name='pinter69'), 15),\n",
       " (Redditor(name='cloud_weather'), 12),\n",
       " (Redditor(name='programmerChilli'), 11),\n",
       " (Redditor(name='sensetime'), 9),\n",
       " (Redditor(name='SpatialComputing'), 8),\n",
       " (Redditor(name='TheInsaneApp'), 7),\n",
       " (Redditor(name='wei_jok'), 7),\n",
       " (Redditor(name='milaworld'), 7),\n",
       " (Redditor(name='Yuqing7'), 7),\n",
       " (Redditor(name='downtownslim'), 6),\n",
       " (Redditor(name='yusuf-bengio'), 5),\n",
       " (Redditor(name='dojoteef'), 5),\n",
       " (Redditor(name='vijish_madhavan'), 4),\n",
       " (Redditor(name='_sshin_'), 4),\n",
       " (Redditor(name='davidbun'), 4),\n",
       " (Redditor(name='othotr'), 4),\n",
       " (Redditor(name='olaf_nij'), 4),\n",
       " (Redditor(name='DeepEven'), 4),\n",
       " (Redditor(name='Wiskkey'), 4),\n",
       " (Redditor(name='SkiddyX'), 4),\n",
       " (Redditor(name='RudyWurlitzer'), 4),\n",
       " (Redditor(name='finallyifoundvalidUN'), 4),\n",
       " (Redditor(name='MassivePellfish'), 4),\n",
       " (Redditor(name='RichardRNN'), 3),\n",
       " (Redditor(name='pathak22'), 3),\n",
       " (Redditor(name='happybirthday290'), 3),\n",
       " (Redditor(name='inarrears'), 3),\n",
       " (Redditor(name='ykilcher'), 3),\n",
       " (Redditor(name='chisai_mikan'), 3),\n",
       " (Redditor(name='smokeonwater234'), 3),\n",
       " (Redditor(name='j_orshman'), 3),\n",
       " (Redditor(name='clbam8'), 3),\n",
       " (Redditor(name='rstoj'), 3),\n",
       " (Redditor(name='shervinea'), 3),\n",
       " (Redditor(name='Neat-Delivery4741'), 3),\n",
       " (Redditor(name='BatmantoshReturns'), 3),\n",
       " (Redditor(name='sentdex'), 3),\n",
       " (Redditor(name='Quantum_Stat'), 3),\n",
       " (Redditor(name='minimaxir'), 3),\n",
       " (Redditor(name='baylearn'), 3),\n",
       " (Redditor(name='regalalgorithm'), 3),\n",
       " (Redditor(name='_ayushp_'), 2),\n",
       " (Redditor(name='Roboserg'), 2),\n",
       " (Redditor(name='e_walker'), 2),\n",
       " (Redditor(name='AtreveteTeTe'), 2),\n",
       " (Redditor(name='nlkey2022'), 2),\n",
       " (Redditor(name='imaginfinity'), 2),\n",
       " (Redditor(name='jsonathan'), 2),\n",
       " (Redditor(name='yunjey'), 2),\n",
       " (Redditor(name='MTGTraner'), 2),\n",
       " (Redditor(name='vadhavaniyafaijan'), 2),\n",
       " (Redditor(name='jeffatgoogle'), 2),\n",
       " (Redditor(name='RelevantMarketing'), 2),\n",
       " (Redditor(name='giugiacaglia'), 2),\n",
       " (Redditor(name='markurtz'), 2),\n",
       " (Redditor(name='good_rice'), 2),\n",
       " (Redditor(name='zimonitrome'), 2),\n",
       " (Redditor(name='davidmezzetti'), 2),\n",
       " (Redditor(name='iFighting'), 2),\n",
       " (Redditor(name='taki0112'), 2),\n",
       " (Redditor(name='BB4evaTB12'), 2),\n",
       " (Redditor(name='jiupinjia'), 2),\n",
       " (Redditor(name='xepo3abp'), 2),\n",
       " (Redditor(name='AlexSnakeKing'), 2),\n",
       " (Redditor(name='Sig_Luna'), 2),\n",
       " (Redditor(name='samim23'), 2),\n",
       " (Redditor(name='__data_science__'), 2),\n",
       " (Redditor(name='lkhphuc'), 2),\n",
       " (Redditor(name='backupcortex'), 2),\n",
       " (Redditor(name='nicolas-gervais'), 2),\n",
       " (Redditor(name='kreyio3i'), 2),\n",
       " (Redditor(name='sksq9'), 2),\n",
       " (Redditor(name='proof_required'), 2),\n",
       " (Redditor(name='q914847518'), 2),\n",
       " (Redditor(name='opensourcecolumbus'), 2),\n",
       " (Redditor(name='meflou'), 2),\n",
       " (Redditor(name='L-MK'), 2),\n",
       " (Redditor(name='siddarth2947'), 2),\n",
       " (Redditor(name='oneweirdkerneltrick'), 2),\n",
       " (Redditor(name='jayalammar'), 2),\n",
       " (Redditor(name='jboyml'), 2),\n",
       " (Redditor(name='PetarVelickovic'), 2),\n",
       " (Redditor(name='tomd_96'), 2),\n",
       " (Redditor(name='chonyyy'), 2),\n",
       " (Redditor(name='thegregyang'), 2),\n",
       " (Redditor(name='ilikepancakez'), 2),\n",
       " (Redditor(name='TiredOldCrow'), 2),\n",
       " (Redditor(name='SleekEagle'), 2),\n",
       " (Redditor(name='OnlyProggingForFun'), 2),\n",
       " (Redditor(name='mistermysterioyster'), 2),\n",
       " (Redditor(name='ch3njust1n'), 2),\n",
       " (Redditor(name='mystikaldanger'), 2),\n",
       " (Redditor(name='Seankala'), 2),\n",
       " (Redditor(name='Kiuhnm'), 2),\n",
       " (Redditor(name='moinnadeem'), 2),\n",
       " (Redditor(name='leogao2'), 2),\n",
       " (Redditor(name='Thomjazz'), 2),\n",
       " (Redditor(name='feedthecreed'), 2),\n",
       " (Redditor(name='wavelander'), 2),\n",
       " (Redditor(name='pmigdal'), 2),\n",
       " (Redditor(name='gohu_cd'), 2),\n",
       " (Redditor(name='mippie_moe'), 2),\n",
       " (Redditor(name='fhuszar'), 2),\n",
       " (Redditor(name='jeremyhoward'), 2),\n",
       " (Redditor(name='cranthir_'), 2),\n",
       " (Redditor(name='bendee983'), 2),\n",
       " (Redditor(name='__Julia'), 2),\n",
       " (Redditor(name='zjost85'), 2),\n",
       " (Redditor(name='gwern'), 2),\n",
       " (Redditor(name='DrPharael'), 2),\n",
       " (Redditor(name='Bayequentist'), 2),\n",
       " (Redditor(name='HAH_official'), 2),\n",
       " (Redditor(name='Eurchus'), 2),\n",
       " (Redditor(name='EducationalCicada'), 2),\n",
       " (Redditor(name='pommedeterresautee'), 2),\n",
       " (Redditor(name='techsucker'), 2),\n",
       " (Redditor(name='dabrot'), 2),\n",
       " (Redditor(name='Shevizzle'), 2),\n",
       " (Redditor(name='ccrbltscm'), 2),\n",
       " (Redditor(name='cyrildiagne'), 1),\n",
       " (Redditor(name='mencil47'), 1),\n",
       " (Redditor(name='Enguzelharf'), 1),\n",
       " (Redditor(name='hzwer'), 1),\n",
       " (Redditor(name='Lairv'), 1),\n",
       " (Redditor(name='maaartiin_mac'), 1),\n",
       " (Redditor(name='grey--area'), 1),\n",
       " (Redditor(name='kilsekddd'), 1),\n",
       " (Redditor(name='Lost-Parfait568'), 1),\n",
       " (Redditor(name='Uncommented_python'), 1),\n",
       " (Redditor(name='stpidhorskyi'), 1),\n",
       " (Redditor(name='DicksDontExist'), 1),\n",
       " (Redditor(name='vic8760'), 1),\n",
       " (Redditor(name='thatguydr'), 1),\n",
       " (Redditor(name='seawee1'), 1),\n",
       " (Redditor(name='toxickettle'), 1),\n",
       " (Redditor(name='AsuharietYgvar'), 1),\n",
       " (Redditor(name='alexeykurov'), 1),\n",
       " (Redditor(name='didntfinishhighschoo'), 1),\n",
       " (Redditor(name='b-3-n-'), 1),\n",
       " (Redditor(name='MrAcurite'), 1),\n",
       " (Redditor(name='-BlackSquirrel-'), 1),\n",
       " (Redditor(name='jonathanbesomi'), 1),\n",
       " (Redditor(name='Excellent_Expert8581'), 1),\n",
       " (Redditor(name='Naughty_Nagaland'), 1),\n",
       " (Redditor(name='nord2rocks'), 1),\n",
       " (Redditor(name='tigeer'), 1),\n",
       " (Redditor(name='konasj'), 1),\n",
       " (Redditor(name='EmbersArc'), 1),\n",
       " (Redditor(name='yoshTM'), 1),\n",
       " (Redditor(name='voidupdate'), 1),\n",
       " (Redditor(name='Flaky_Suit_8665'), 1),\n",
       " (Redditor(name='_gmark_'), 1),\n",
       " (Redditor(name='AGI_aint_happening'), 1),\n",
       " (Redditor(name='adriacabeza'), 1),\n",
       " (Redditor(name='FelipeMarcelino'), 1),\n",
       " (Redditor(name='OriolVinyals'), 1),\n",
       " (Redditor(name='Kickuchiyo'), 1),\n",
       " (Redditor(name='dmitry_ulyanov'), 1),\n",
       " (Redditor(name='No-Challenge-4770'), 1),\n",
       " (Redditor(name='NoisesMaker'), 1),\n",
       " (Redditor(name='undefdev'), 1),\n",
       " (Redditor(name='orange-erotic-bible'), 1),\n",
       " (Redditor(name='coolwulf'), 1),\n",
       " (Redditor(name='jettico'), 1),\n",
       " (Redditor(name='SethBling'), 1),\n",
       " (Redditor(name='a19n'), 1),\n",
       " (Redditor(name='Another__one'), 1),\n",
       " (Redditor(name='tanelai'), 1),\n",
       " (Redditor(name='dronecub'), 1),\n",
       " (Redditor(name='mgdmw'), 1),\n",
       " (Redditor(name='chatterbox272'), 1),\n",
       " (Redditor(name='lexfridman'), 1),\n",
       " (Redditor(name='ajcvedia'), 1),\n",
       " (Redditor(name='mingyuliutw'), 1),\n",
       " (Redditor(name='Mediocre-Bullfrog686'), 1),\n",
       " (Redditor(name='begooboi'), 1),\n",
       " (Redditor(name='infinitlybana'), 1),\n",
       " (Redditor(name='omniscientclown'), 1),\n",
       " (Redditor(name='willardwillson'), 1),\n",
       " (Redditor(name='geaxart'), 1),\n",
       " (Redditor(name='nicolasap'), 1),\n",
       " (Redditor(name='Sardonyx001'), 1),\n",
       " (Redditor(name='fippy24'), 1),\n",
       " (Redditor(name='crp1994'), 1),\n",
       " (Redditor(name='adversary_argument'), 1),\n",
       " (Redditor(name='Only_Assist'), 1),\n",
       " (Redditor(name='j_lyf'), 1),\n",
       " (Redditor(name='sanic_the_hedgefond'), 1),\n",
       " (Redditor(name='fromnighttilldawn'), 1),\n",
       " (Redditor(name='Routine-Coffee8832'), 1),\n",
       " (Redditor(name='turtlesoup'), 1),\n",
       " (Redditor(name='SquirrelOnTheDam'), 1),\n",
       " (Redditor(name='mrconter1'), 1),\n",
       " (Redditor(name='cwkx'), 1),\n",
       " (Redditor(name='shaggorama'), 1),\n",
       " (Redditor(name='Bowserwolf1'), 1),\n",
       " (Redditor(name='seraschka'), 1),\n",
       " (Redditor(name='donkey_strom16001'), 1),\n",
       " (Redditor(name='actbsh'), 1),\n",
       " (Redditor(name='matthias_buehlmann'), 1),\n",
       " (Redditor(name='MetaAI_Official'), 1),\n",
       " (Redditor(name='jkterry1'), 1),\n",
       " (Redditor(name='ksinkar'), 1),\n",
       " (Redditor(name='iamkeyur'), 1),\n",
       " (Redditor(name='elftim'), 1),\n",
       " (Redditor(name='deadtreescrolls'), 1),\n",
       " (Redditor(name='Yggdrasil524'), 1),\n",
       " (Redditor(name='peeyek'), 1),\n",
       " (Redditor(name='logicallyzany'), 1),\n",
       " (Redditor(name='Neutran'), 1),\n",
       " (Redditor(name='rockwilly'), 1),\n",
       " (Redditor(name='nickelcore'), 1),\n",
       " (Redditor(name='noidenilec'), 1),\n",
       " (Redditor(name='netw0rkf10w'), 1),\n",
       " (Redditor(name='scan33scan33'), 1),\n",
       " (Redditor(name='robintwhite'), 1),\n",
       " (Redditor(name='blatant_variable'), 1),\n",
       " (Redditor(name='ElegantFeeling'), 1),\n",
       " (Redditor(name='Mogady'), 1),\n",
       " (Redditor(name='pp314159'), 1),\n",
       " (Redditor(name='the_scign'), 1),\n",
       " (Redditor(name='aloser'), 1),\n",
       " (Redditor(name='afeder_'), 1),\n",
       " (Redditor(name='lorenzkuhn'), 1),\n",
       " (Redditor(name='ProGamerGov'), 1),\n",
       " (Redditor(name='Atarust'), 1),\n",
       " (Redditor(name='deepPurpleHaze'), 1),\n",
       " (Redditor(name='julbern'), 1),\n",
       " (Redditor(name='wojti_zielon'), 1),\n",
       " (Redditor(name='m___ke'), 1),\n",
       " (Redditor(name='Britney-Ramona'), 1),\n",
       " (Redditor(name='nmkd'), 1),\n",
       " (Redditor(name='gergi'), 1),\n",
       " (Redditor(name='ghost_agni'), 1),\n",
       " (Redditor(name='adforn'), 1),\n",
       " (Redditor(name='juliaferraioli'), 1),\n",
       " (Redditor(name='idlab-media'), 1),\n",
       " (Redditor(name='mark-v'), 1),\n",
       " (Redditor(name='Discordy'), 1),\n",
       " (Redditor(name='VodkaHaze'), 1),\n",
       " (Redditor(name='sorrge'), 1),\n",
       " (Redditor(name='trikkuz'), 1),\n",
       " (Redditor(name='pwang99'), 1),\n",
       " (Redditor(name='Better_Leg'), 1),\n",
       " (Redditor(name='MassiveContact'), 1),\n",
       " (Redditor(name='PhYsIcS-GUY227'), 1),\n",
       " (Redditor(name='SirLordDragon'), 1),\n",
       " (Redditor(name='timmyriddle'), 1),\n",
       " (Redditor(name='Altruistic-Dot4513'), 1),\n",
       " (Redditor(name='init__27'), 1),\n",
       " (Redditor(name='sour_losers'), 1),\n",
       " (Redditor(name='cherls'), 1),\n",
       " (Redditor(name='friedronaldo'), 1),\n",
       " (Redditor(name='sverzijl'), 1),\n",
       " (Redditor(name='swifty8883'), 1),\n",
       " (Redditor(name='TrainYourMonkeyBrain'), 1),\n",
       " (Redditor(name='Ouitos'), 1),\n",
       " (Redditor(name='m_kardas'), 1),\n",
       " (Redditor(name='upulbandara'), 1),\n",
       " (Redditor(name='mln000b'), 1),\n",
       " (Redditor(name='HashiamKadhim'), 1),\n",
       " (Redditor(name='Eeemonts'), 1),\n",
       " (Redditor(name='rjkb041'), 1),\n",
       " (Redditor(name='Tesg9029'), 1),\n",
       " (Redditor(name='faceshapeapp'), 1),\n",
       " (Redditor(name='stefsietz'), 1),\n",
       " (Redditor(name='deeprnn'), 1),\n",
       " (Redditor(name='PugglesMcPuggle'), 1),\n",
       " (Redditor(name='generalizederror'), 1),\n",
       " (Redditor(name='sensei_von_bonzai'), 1),\n",
       " (Redditor(name='jezeq'), 1),\n",
       " (Redditor(name='AquaHug'), 1),\n",
       " (Redditor(name='danielcar'), 1),\n",
       " (Redditor(name='SlobodanTankovic'), 1),\n",
       " (Redditor(name='persianprez'), 1),\n",
       " (Redditor(name='ConfidentMushroom'), 1),\n",
       " (Redditor(name='madhav1113'), 1),\n",
       " (Redditor(name='yamqwe'), 1),\n",
       " (Redditor(name='Uriopass'), 1),\n",
       " (Redditor(name='Leather-Band-5633'), 1),\n",
       " (Redditor(name='crouching_dragon_420'), 1),\n",
       " (Redditor(name='Playgroundai'), 1),\n",
       " (Redditor(name='omarsar'), 1),\n",
       " (Redditor(name='jamesonatfritz'), 1),\n",
       " (Redditor(name='UIPDsmokes'), 1),\n",
       " (Redditor(name='ArdArt'), 1),\n",
       " (Redditor(name='bonkerfield'), 1),\n",
       " (Redditor(name='posteriorprior'), 1),\n",
       " (Redditor(name='surelyouarejoking'), 1),\n",
       " (Redditor(name='libreland'), 1),\n",
       " (Redditor(name='NFB42'), 1),\n",
       " (Redditor(name='seann999'), 1),\n",
       " (Redditor(name='noobbodyjourney'), 1),\n",
       " (Redditor(name='elchetis'), 1),\n",
       " (Redditor(name='theirfReddit'), 1),\n",
       " (Redditor(name='ai_yoda'), 1),\n",
       " (Redditor(name='GlassPut'), 1),\n",
       " (Redditor(name='rockyrey_w'), 1),\n",
       " (Redditor(name='AdditionalWay'), 1),\n",
       " (Redditor(name='mildlycalm'), 1),\n",
       " (Redditor(name='instantlybanned'), 1),\n",
       " (Redditor(name='xifixi'), 1),\n",
       " (Redditor(name='larseidnes'), 1),\n",
       " (Redditor(name='DisastrousProgrammer'), 1),\n",
       " (Redditor(name='hwoolery'), 1),\n",
       " (Redditor(name='visarga'), 1),\n",
       " (Redditor(name='RichardSSutton'), 1),\n",
       " (Redditor(name='waymo'), 1),\n",
       " (Redditor(name='abstractcontrol'), 1),\n",
       " (Redditor(name='TParcollet'), 1),\n",
       " (Redditor(name='kvfrans'), 1),\n",
       " (Redditor(name='hackpert'), 1),\n",
       " (Redditor(name='jdwittenauer'), 1),\n",
       " (Redditor(name='rosstaylor90'), 1),\n",
       " (Redditor(name='ashutoshbsathe'), 1),\n",
       " (Redditor(name='tomhamer5'), 1),\n",
       " (Redditor(name='Wild_Quiet8627'), 1),\n",
       " (Redditor(name='Philipp'), 1),\n",
       " (Redditor(name='thymeyon'), 1),\n",
       " (Redditor(name='haithamb123'), 1),\n",
       " (Redditor(name='shrine'), 1),\n",
       " (Redditor(name='_bskaggs'), 1),\n",
       " (Redditor(name='xutw21'), 1),\n",
       " (Redditor(name='StellaAthena'), 1),\n",
       " (Redditor(name='binary_zeitgeist'), 1),\n",
       " (Redditor(name='Insighteous'), 1),\n",
       " (Redditor(name='binaryfor'), 1),\n",
       " (Redditor(name='Ok_Mountain_5674'), 1),\n",
       " (Redditor(name='seyedhn'), 1),\n",
       " (Redditor(name='ClaudeCoulombe'), 1),\n",
       " (Redditor(name='UpdraftDev'), 1),\n",
       " (Redditor(name='sloppybird'), 1),\n",
       " (Redditor(name='levviinn'), 1),\n",
       " (Redditor(name='tlkh'), 1),\n",
       " (Redditor(name='beltsazar'), 1),\n",
       " (Redditor(name='nearning'), 1),\n",
       " (Redditor(name='drrelyea'), 1),\n",
       " (Redditor(name='gwen0927'), 1),\n",
       " (Redditor(name='patrickkidger'), 1),\n",
       " (Redditor(name='cgnorthcutt'), 1),\n",
       " (Redditor(name='glassmountain'), 1),\n",
       " (Redditor(name='drlukeor'), 1),\n",
       " (Redditor(name='triplehelix_'), 1),\n",
       " (Redditor(name='Dasomeone'), 1),\n",
       " (Redditor(name='mmbronstein'), 1),\n",
       " (Redditor(name='theXYZT'), 1),\n",
       " (Redditor(name='GoochCommander'), 1),\n",
       " (Redditor(name='thecity2'), 1),\n",
       " (Redditor(name='e2v-sde-parody'), 1),\n",
       " (Redditor(name='some_q'), 1),\n",
       " (Redditor(name='redlow0992'), 1),\n",
       " (Redditor(name='nomaderx'), 1),\n",
       " (Redditor(name='AlphaHumanZero'), 1),\n",
       " (Redditor(name='jerryli27'), 1),\n",
       " (Redditor(name='Minkkowski'), 1),\n",
       " (Redditor(name='WORDSALADSANDWICH'), 1),\n",
       " (Redditor(name='guilIaume'), 1),\n",
       " (Redditor(name='DIAMBRA_AIArena'), 1),\n",
       " (Redditor(name='pure_x01'), 1),\n",
       " (Redditor(name='gwulfs'), 1),\n",
       " (Redditor(name='fedegarzar'), 1),\n",
       " (Redditor(name='LoveMetal'), 1),\n",
       " (Redditor(name='tim_anglade'), 1),\n",
       " (Redditor(name='ardula99'), 1),\n",
       " (Redditor(name='baekalfen'), 1),\n",
       " (Redditor(name='northwestredditor'), 1),\n",
       " (Redditor(name='black0017'), 1),\n",
       " (Redditor(name='hardik_kamboj'), 1),\n",
       " (Redditor(name='the21st'), 1),\n",
       " (Redditor(name='1101010101010101'), 1),\n",
       " (Redditor(name='pierrelux'), 1),\n",
       " (Redditor(name='SuccMyStrangerThings'), 1),\n",
       " (Redditor(name='nevereallybored'), 1),\n",
       " (Redditor(name='jd_3d'), 1),\n",
       " (Redditor(name='No-Recommendation384'), 1),\n",
       " (Redditor(name='big_skapinsky'), 1),\n",
       " (Redditor(name='wandering_tsilihin'), 1),\n",
       " (Redditor(name='andrewyng'), 1),\n",
       " (Redditor(name='pier4r'), 1),\n",
       " (Redditor(name='AlertSignificance5'), 1),\n",
       " (Redditor(name='mavenchist'), 1),\n",
       " (Redditor(name='SerpentAI'), 1),\n",
       " (Redditor(name='peterboothvt'), 1),\n",
       " (Redditor(name='Remi_Coulom'), 1),\n",
       " (Redditor(name='KarlKastor'), 1),\n",
       " (Redditor(name='SorollmefurtherBitch'), 1),\n",
       " (Redditor(name='SoFarFromHome'), 1),\n",
       " (Redditor(name='keurigg'), 1),\n",
       " (Redditor(name='gabrielgoh'), 1),\n",
       " (Redditor(name='clr715'), 1),\n",
       " (Redditor(name='_chaz_'), 1),\n",
       " (Redditor(name='Svito-zar'), 1),\n",
       " (Redditor(name='orangeduck'), 1),\n",
       " (Redditor(name='lcgomes'), 1),\n",
       " (Redditor(name='mltidbits'), 1),\n",
       " (Redditor(name='distant_gradient'), 1),\n",
       " (Redditor(name='Mjjjokes'), 1),\n",
       " (Redditor(name='unnamedn00b'), 1),\n",
       " (Redditor(name='neuralnets120'), 1),\n",
       " (Redditor(name='Spotlight0xff'), 1),\n",
       " (Redditor(name='jay_jay_man'), 1),\n",
       " (Redditor(name='dr_ish'), 1),\n",
       " (Redditor(name='justheuristic'), 1),\n",
       " (Redditor(name='aiismorethanml'), 1),\n",
       " (Redditor(name='Inori'), 1),\n",
       " (Redditor(name='AlanZucconi'), 1),\n",
       " (Redditor(name='divideconcept'), 1),\n",
       " (Redditor(name='pit_station'), 1),\n",
       " (Redditor(name='ContributionSecure14'), 1),\n",
       " (Redditor(name='omniron'), 1),\n",
       " (Redditor(name='fanboy-1985'), 1),\n",
       " (Redditor(name='dasayan05'), 1),\n",
       " (Redditor(name='SnoozeDoggyDog'), 1),\n",
       " (Redditor(name='joyyeki'), 1),\n",
       " (Redditor(name='orenmatar'), 1),\n",
       " (Redditor(name='ureepamuree'), 1),\n",
       " (Redditor(name='novak-99'), 1),\n",
       " (Redditor(name='Jazzlike-Disaster-67'), 1),\n",
       " (Redditor(name='SupraluminalShift'), 1),\n",
       " (Redditor(name='hnipun'), 1),\n",
       " (Redditor(name='ACAIworkshop'), 1),\n",
       " (Redditor(name='asobolev'), 1),\n",
       " (Redditor(name='davis685'), 1),\n",
       " (Redditor(name='Wookai'), 1),\n",
       " (Redditor(name='meowklaski'), 1),\n",
       " (Redditor(name='EveryDay-NormalGuy'), 1),\n",
       " (Redditor(name='gfursin'), 1),\n",
       " (Redditor(name='alievk91'), 1),\n",
       " (Redditor(name='MLknowledge'), 1),\n",
       " (Redditor(name='cldud1245'), 1),\n",
       " (Redditor(name='aiforworld2'), 1),\n",
       " (Redditor(name='anshbansal'), 1),\n",
       " (Redditor(name='bobchennan'), 1),\n",
       " (Redditor(name='verfahrensweise'), 1),\n",
       " (Redditor(name='JavierFnts'), 1),\n",
       " (Redditor(name='brandinho77'), 1),\n",
       " (Redditor(name='rlesii'), 1),\n",
       " (Redditor(name='insider_7'), 1),\n",
       " (Redditor(name='FirstTimeResearcher'), 1),\n",
       " (Redditor(name='Other-Top'), 1),\n",
       " (Redditor(name='purplebrown_updown'), 1),\n",
       " (Redditor(name='c0cky_'), 1),\n",
       " (Redditor(name='David_Silver'), 1),\n",
       " (Redditor(name='asingh33'), 1),\n",
       " (Redditor(name='rui_'), 1),\n",
       " (Redditor(name='jikkii'), 1),\n",
       " (Redditor(name='waf04'), 1),\n",
       " (Redditor(name='Luolc'), 1),\n",
       " (Redditor(name='mydogecute'), 1),\n",
       " (Redditor(name='Gear5th'), 1),\n",
       " (Redditor(name='hughbzhang'), 1),\n",
       " (Redditor(name='shannoncoin'), 1),\n",
       " (Redditor(name='SpockTriesToReturn'), 1),\n",
       " (Redditor(name='dadadidi'), 1),\n",
       " (Redditor(name='ArtBears'), 1),\n",
       " (Redditor(name='CrankyBear'), 1),\n",
       " (Redditor(name='givdwiel'), 1),\n",
       " (Redditor(name='tr1pzz'), 1),\n",
       " (Redditor(name='henrythepaw'), 1),\n",
       " (Redditor(name='demegir'), 1),\n",
       " (Redditor(name='invertedpassion'), 1),\n",
       " (Redditor(name='hcarlens'), 1),\n",
       " (Redditor(name='EmergenceIsMagic'), 1),\n",
       " (Redditor(name='ofirpress'), 1),\n",
       " (Redditor(name='thebackpropaganda'), 1),\n",
       " (Redditor(name='thomasdav_is'), 1),\n",
       " (Redditor(name='IlyaSutskever'), 1),\n",
       " (Redditor(name='jrieke'), 1),\n",
       " (Redditor(name='axsauze'), 1),\n",
       " (Redditor(name='ylecun'), 1),\n",
       " (Redditor(name='AuspiciousApple'), 1),\n",
       " (Redditor(name='highergraphic'), 1),\n",
       " (Redditor(name='Enish-go-on-dosh'), 1),\n",
       " (Redditor(name='kmario23'), 1),\n",
       " (Redditor(name='rd11235'), 1),\n",
       " (Redditor(name='enryu42'), 1),\n",
       " (Redditor(name='Superb-Drawer5214'), 1),\n",
       " (Redditor(name='SergiosKar'), 1),\n",
       " (Redditor(name='Davidobot'), 1),\n",
       " (Redditor(name='dancepm'), 1),\n",
       " (Redditor(name='Va_Linor'), 1),\n",
       " (Redditor(name='desku'), 1),\n",
       " (Redditor(name='shonburton'), 1),\n",
       " (Redditor(name='Independent_Snoo'), 1),\n",
       " (Redditor(name='geoffhinton'), 1),\n",
       " (Redditor(name='Xeroko'), 1),\n",
       " (Redditor(name='PuzzledProgrammer3'), 1),\n",
       " (Redditor(name='russellsparadox101'), 1),\n",
       " (Redditor(name='Kitchen_Extreme'), 1),\n",
       " (Redditor(name='scalar_flow'), 1),\n",
       " (Redditor(name='bahidev'), 1),\n",
       " (Redditor(name='dabshitty'), 1),\n",
       " (Redditor(name='ai-lover'), 1),\n",
       " (Redditor(name='brtek'), 1),\n",
       " (Redditor(name='shoeblade'), 1),\n",
       " (Redditor(name='erogol'), 1),\n",
       " (Redditor(name='mrborgen86'), 1),\n",
       " (Redditor(name='mp04205'), 1),\n",
       " (Redditor(name='ekerazha'), 1),\n",
       " (Redditor(name='positivelysemidef'), 1),\n",
       " (Redditor(name='hellopaperspace'), 1),\n",
       " (Redditor(name='crypto_ha'), 1),\n",
       " (Redditor(name='tweninger'), 1),\n",
       " (Redditor(name='mltoss'), 1),\n",
       " (Redditor(name='nepowoes'), 1),\n",
       " (Redditor(name='style2paints'), 1),\n",
       " (Redditor(name='FredrikNoren'), 1),\n",
       " (Redditor(name='caedin8'), 1),\n",
       " (Redditor(name='tmpberk'), 1),\n",
       " (Redditor(name='Hartvik'), 1),\n",
       " (Redditor(name='alxndrkalinin'), 1),\n",
       " (Redditor(name='whiteshadow13'), 1),\n",
       " (Redditor(name='DragonLord9'), 1),\n",
       " (Redditor(name='moein-shariatnia'), 1),\n",
       " (Redditor(name='vakker00'), 1),\n",
       " (Redditor(name='wkilpan'), 1),\n",
       " (Redditor(name='Veedrac'), 1),\n",
       " (Redditor(name='abnormdist'), 1),\n",
       " (Redditor(name='fireless-phoenix'), 1),\n",
       " (Redditor(name='pcaversaccio'), 1),\n",
       " (Redditor(name='born_in_cyberspace'), 1),\n",
       " (Redditor(name='ourannual'), 1),\n",
       " (Redditor(name='Zeta_36'), 1),\n",
       " (Redditor(name='mmeartine'), 1),\n",
       " (Redditor(name='liqui_date_me'), 1),\n",
       " (Redditor(name='fumingelephant'), 1),\n",
       " (Redditor(name='sobe86'), 1),\n",
       " (Redditor(name='Professor_Entropy'), 1),\n",
       " (Redditor(name='Death_Water'), 1),\n",
       " (Redditor(name='Egan_Fan'), 1),\n",
       " (Redditor(name='pramook'), 1),\n",
       " (Redditor(name='benkoller'), 1),\n",
       " (Redditor(name='Xirious'), 1),\n",
       " (Redditor(name='hides_dirty_secrets'), 1),\n",
       " (Redditor(name='int8blog'), 1),\n",
       " (Redditor(name='testic'), 1),\n",
       " (Redditor(name='carpedm20'), 1),\n",
       " (Redditor(name='jakes0080'), 1),\n",
       " (Redditor(name='lyeoni'), 1),\n",
       " (Redditor(name='jack-of-some'), 1),\n",
       " (Redditor(name='nedflanders1976'), 1),\n",
       " (Redditor(name='tuscanresearcher'), 1),\n",
       " (Redditor(name='vwxyzjn'), 1),\n",
       " (Redditor(name='krallistic'), 1),\n",
       " (Redditor(name='DavidCode'), 1),\n",
       " (Redditor(name='KaleidoscopeBest1569'), 1),\n",
       " (Redditor(name='radome9'), 1),\n",
       " (Redditor(name='eamonnkeogh'), 1),\n",
       " (Redditor(name='sergeyfeldman'), 1),\n",
       " (Redditor(name='stripathi08'), 1),\n",
       " (Redditor(name='JosephLChu'), 1),\n",
       " (Redditor(name='TheSiersciuch'), 1),\n",
       " (Redditor(name='rasmii'), 1),\n",
       " (Redditor(name='bo_peng'), 1),\n",
       " (Redditor(name='ezubaric'), 1),\n",
       " (Redditor(name='JaneXWang'), 1),\n",
       " (Redditor(name='jinpanZe'), 1),\n",
       " (Redditor(name='romangarnett'), 1),\n",
       " (Redditor(name='AxeLond'), 1),\n",
       " (Redditor(name='krinart'), 1),\n",
       " (Redditor(name='DIY_surgery'), 1),\n",
       " (Redditor(name='cavedave'), 1),\n",
       " (Redditor(name='often_worried'), 1),\n",
       " (Redditor(name='Corp-Por'), 1),\n",
       " (Redditor(name='yliopisto420'), 1),\n",
       " (Redditor(name='SlickBlueML'), 1),\n",
       " (Redditor(name='universome'), 1),\n",
       " (Redditor(name='rayryeng'), 1),\n",
       " (Redditor(name='ClydeMachine'), 1),\n",
       " (Redditor(name='Hazalem'), 1),\n",
       " (Redditor(name='KirillTheMunchKing'), 1),\n",
       " (Redditor(name='aveni0'), 1),\n",
       " (Redditor(name='faridrashidi'), 1),\n",
       " (Redditor(name='m_nemo_syne'), 1),\n",
       " (Redditor(name='fripperML'), 1),\n",
       " (Redditor(name='abananachspace'), 1),\n",
       " (Redditor(name='Boom_Various'), 1),\n",
       " (Redditor(name='AdversarialDomain'), 1),\n",
       " (Redditor(name='Graphics4Life'), 1),\n",
       " (Redditor(name='samb-t'), 1),\n",
       " (Redditor(name='howdygoop'), 1),\n",
       " (Redditor(name='okbus987'), 1),\n",
       " (Redditor(name='mrahtz'), 1),\n",
       " (Redditor(name='AlexeyAB'), 1),\n",
       " (Redditor(name='etienne_ben'), 1),\n",
       " (Redditor(name='flotothemoon'), 1),\n",
       " (Redditor(name='dexter89_kp'), 1),\n",
       " (Redditor(name='luspra'), 1),\n",
       " (Redditor(name='ITConnected'), 1),\n",
       " (Redditor(name='modeless'), 1),\n",
       " (Redditor(name='DJYEEZYWORLDPEACE'), 1),\n",
       " (Redditor(name='p1esk'), 1),\n",
       " (Redditor(name='MysteryInc152'), 1),\n",
       " (Redditor(name='htahir1'), 1),\n",
       " (Redditor(name='Mister_Abc'), 1),\n",
       " (Redditor(name='Left_Ad8361'), 1),\n",
       " (Redditor(name='iphysic'), 1),\n",
       " (Redditor(name='open_nsfw'), 1),\n",
       " (Redditor(name='chuong98'), 1),\n",
       " (Redditor(name='leadersprize'), 1),\n",
       " (Redditor(name='atplwl'), 1),\n",
       " (Redditor(name='Gumeo'), 1),\n",
       " (Redditor(name='michael_htx'), 1),\n",
       " (Redditor(name='selva86'), 1),\n",
       " (Redditor(name='defense1011'), 1),\n",
       " (Redditor(name='i_am_squishy'), 1),\n",
       " (Redditor(name='rushter_'), 1),\n",
       " (Redditor(name='LLCoolZ'), 1),\n",
       " (Redditor(name='mwitiderrick'), 1),\n",
       " (Redditor(name='kaoshost'), 1),\n",
       " (Redditor(name='b06901038g'), 1),\n",
       " (Redditor(name='fasttosmile'), 1),\n",
       " (Redditor(name='bryang217'), 1),\n",
       " (Redditor(name='galapag0'), 1),\n",
       " (Redditor(name='joshgreaves'), 1),\n",
       " (Redditor(name='vonnik'), 1),\n",
       " (Redditor(name='Old-Library4938'), 1),\n",
       " (Redditor(name='vdutor'), 1),\n",
       " (Redditor(name='Azuresonance'), 1),\n",
       " (Redditor(name='DreamFlasher'), 1),\n",
       " (Redditor(name='kris33'), 1),\n",
       " (Redditor(name='AdelSexy'), 1),\n",
       " (Redditor(name='amitness'), 1),\n",
       " (Redditor(name='QMred'), 1),\n",
       " (Redditor(name='angry-zergling'), 1),\n",
       " (Redditor(name='slavivanov'), 1),\n",
       " (Redditor(name='bdamos'), 1),\n",
       " (Redditor(name='odinnotdoit'), 1),\n",
       " (Redditor(name='permalip'), 1),\n",
       " (Redditor(name='That_Violinist_18'), 1),\n",
       " (Redditor(name='madredditscientist'), 1),\n",
       " (Redditor(name='kit1980'), 1),\n",
       " (Redditor(name='seesawtron'), 1),\n",
       " (Redditor(name='learningsystem'), 1),\n",
       " (Redditor(name='bulc381'), 1),\n",
       " (Redditor(name='perone'), 1),\n",
       " (Redditor(name='svantana'), 1),\n",
       " (Redditor(name='hardcoresoftware'), 1),\n",
       " (Redditor(name='noahgolm'), 1),\n",
       " (Redditor(name='joaoperfig'), 1),\n",
       " (Redditor(name='mtngld'), 1),\n",
       " (Redditor(name='FactfulX'), 1),\n",
       " (Redditor(name='ahmedbesbes'), 1),\n",
       " (Redditor(name='Frosty-Heron3972'), 1),\n",
       " (Redditor(name='rafgro'), 1),\n",
       " (Redditor(name='ageitgey'), 1),\n",
       " (Redditor(name='jeremybmerrill'), 1),\n",
       " (Redditor(name='hithesh111'), 1),\n",
       " (Redditor(name='Rynsin'), 1),\n",
       " (Redditor(name='VanVeenGames'), 1),\n",
       " (Redditor(name='elanmart'), 1),\n",
       " (Redditor(name='ImBradleyKim'), 1),\n",
       " (Redditor(name='029187'), 1),\n",
       " (Redditor(name='abbumm'), 1),\n",
       " (Redditor(name='machinesaredumb'), 1),\n",
       " (Redditor(name='SilentTheme'), 1),\n",
       " (Redditor(name='emilwallner'), 1),\n",
       " (Redditor(name='tsauri'), 1),\n",
       " (Redditor(name='danielhanchen'), 1)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "top_posts = s_ml.top(limit=1000)\n",
    "authors = []\n",
    "for post in top_posts:\n",
    "    authors.append(post.author)\n",
    "    \n",
    "counts = Counter(authors)\n",
    "counts.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üíΩ‚ùì Data Question:\n",
    "\n",
    "6. Does there seem to be a large distribution of posters or a smaller concentration of posters who are very active? What kind of impact might this have on the data?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the top 1000 posts there does seem to be a reasonably large distribution of posters but only few of them have multiple posts and the number is even less if we look at 10s of posts. That is going to give a view that is more biased based on those authors opinions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "vscode": {
   "interpreter": {
    "hash": "c57794392b841cffd8686d5c4548e4e2ec78521f49300d60954d1380f1b4bd1f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
